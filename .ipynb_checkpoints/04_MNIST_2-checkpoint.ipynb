{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "AwErIR3bzMUh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda:0\n",
      "path.ls: [Path('/home/jovyan/work/data/mnist_sample/train'), Path('/home/jovyan/work/data/mnist_sample/valid'), Path('/home/jovyan/work/data/mnist_sample/labels.csv')], path.pwd: /home/jovyan/work/data/mnist_sample\n"
     ]
    }
   ],
   "source": [
    "# Install required pip packages, import needed libraries, mount google drive in colab notebooks,\n",
    "# set BASE_DIR, set device to cpu or gpu based on what's available, download dataset\n",
    "\n",
    "# !pip install -Uqq fastbook ipywidgets nbdev\n",
    "\n",
    "import fastbook\n",
    "fastbook.setup_book()\n",
    "from fastbook import *\n",
    "from fastai.vision.widgets import *\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive', force_remount=True)\n",
    "# your drive home will be at /content/gdrive/MyDrive/\n",
    "# your notebooks might be at /content/gdrive/MyDrive/Colab Notebooks/\n",
    "# BASE_DIR = \"/content/gdrive/MyDrive/Colab Notebooks/\"\n",
    "BASE_DIR = \"/home/jovyan/work\"\n",
    "\n",
    "# https://wandb.ai/wandb/common-ml-errors/reports/How-To-Use-GPU-with-PyTorch---VmlldzozMzAxMDk\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'using device: {device}')\n",
    "\n",
    "# !export FASTAI_HOME=/home/jovyan/work\n",
    "path = untar_data(URLs.MNIST_SAMPLE, data=f'{BASE_DIR}/data')\n",
    "print(f'path.ls: {path.ls()}, path.pwd: {path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "xJVei1jB0I0Q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]]), \n",
      "b: tensor([[7, 7]]), \n",
      "cat(): tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [7., 7.]]), \n",
      "view(): tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 7., 7.]])\n",
      "t: tensor([1, 1, 1, 0, 0, 0, 0])\n",
      "unsqueeze(0): tensor([[1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]])\n",
      "unsqueeze(1): tensor([[1, 1, 1, 0, 0, 0, 0]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.]]),\n",
       " tensor(6.),\n",
       " tensor(1.))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How do the pytorch functions cat(), view(), unsqueeze(), sum() and mean() work\n",
    "\n",
    "# ??torch.cat\n",
    "# ??torch.view\n",
    "# ??torch.unsqueeze\n",
    "# ??torch.sum\n",
    "# ??torch.mean\n",
    "\n",
    "\n",
    "a = torch.ones(3, 2)\n",
    "b = torch.full((1, 2), 7)\n",
    "c = torch.full((1, 4, 3), 3)\n",
    "print(f'a: {a}, \\nb: {b}, \\ncat(): {torch.cat([a, b])}, \\nview(): {torch.cat([a, b]).view(-1, 4)}')\n",
    "\n",
    "# valid values for unsqueeze in this example: -2 to 1\n",
    "t = tensor([1]*3 + [0]*4)\n",
    "print(f't: {t}')\n",
    "print(f'unsqueeze(0): {t.unsqueeze(1)}')\n",
    "print(f'unsqueeze(1): {t.unsqueeze(0)}')\n",
    "\n",
    "a, a.sum(), a.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "vmunicOYzUtK"
   },
   "outputs": [],
   "source": [
    "# Convert MNIST data in folders to the format we need\n",
    "# 1. Open each image file as an Image object and convert it to tensors\n",
    "# 2. Convert a list of 2D tensors to a 3D tensor using stack(), normalise\n",
    "#     by converting each value to a float and dividing by max pixel value 255\n",
    "# 3. Concatenate all the tensors of 3s and 7s together and make 28x28 arrays\n",
    "#     into a 28*28 length list\n",
    "# 4. Creatae the labels such that we have 1 for image '3' and 0 for image '7'\n",
    "\n",
    "def filesToStackedTensors(d1, d2):\n",
    "  t = [tensor(Image.open(f)).to(device) for f in (path/d1/d2).ls().sorted()]\n",
    "  return torch.stack(t, 0).float()/255\n",
    "\n",
    "def x_y(stacked_x, stacked_y):\n",
    "  x = torch.cat([stacked_x, stacked_y]).view(-1, 28*28)\n",
    "  y = tensor([1]*len(stacked_x) + [0]*len(stacked_y)).unsqueeze(1).to(device)\n",
    "  return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "8MifxbiyzqbY"
   },
   "outputs": [],
   "source": [
    "# set the values of train_x, train_y, valid_x and valid_y\n",
    "\n",
    "train_x, train_y = x_y(filesToStackedTensors('train', '3'), \\\n",
    "                       filesToStackedTensors('train', '7'))\n",
    "valid_x, valid_y = x_y(filesToStackedTensors('valid', '3'), \\\n",
    "                       filesToStackedTensors('valid', '7'))\n",
    "# train_x.shape, train_y.shape, valid_x.shape, valid_y.shape\n",
    "# print(f'x cuda? {train_x.is_cuda}')\n",
    "# print(f'y cuda? {train_y.is_cuda}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[-0.7658, -0.7506],\n",
      "        [ 1.3525,  0.6863],\n",
      "        [-0.3278,  0.7950]]), \n",
      "y: tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[0., 0.],\n",
      "        [1., 1.],\n",
      "        [0., 1.]])\n",
      "tensor([[1.0000, 1.0000],\n",
      "        [1.3525, 0.6863],\n",
      "        [1.0000, 0.7950]])\n"
     ]
    }
   ],
   "source": [
    "# How does pytorch function where() work\n",
    "# https://pytorch.org/docs/stable/generated/torch.where.html\n",
    "\n",
    "#??torch.where\n",
    "\n",
    "x = torch.randn(3, 2)\n",
    "y = torch.ones(3, 2)\n",
    "print(f'x: {x}, \\ny: {y}')\n",
    "print(torch.where(x > 0, 1.0, 0.0))\n",
    "print(torch.where(x > 0, x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "rJb62k2lNh6c"
   },
   "outputs": [],
   "source": [
    "# define functions to represent the model(predictions), loss function(loss) and apply gradient descent algorithm\n",
    "# n number of times(apply_step & apply_steps)\n",
    "\n",
    "def predictions(x, w, b):\n",
    "  r = x@w + b\n",
    "  # print(f'r.grad_fn: {r.grad_fn}')\n",
    "  # print(f'r shape: {r.shape}, r: {r[0:4, 0:4]}')\n",
    "  # sums = (r.sum(1)).unsqueeze(1)\n",
    "  # print(f'sums.grad_fn: {sums.grad_fn}')\n",
    "  # print(f'sums shape: {sums.shape}, sums: {sums[0:4]}')\n",
    "  sig = torch.sigmoid(r)\n",
    "  # print(f'sig.grad_fn: {sig.grad_fn}')\n",
    "  # print(f'sig shape: {sig.shape}, sig: {sig[0:4]}')\n",
    "  # print(f'sig: {sig[0:4]}, sig.sum: {sig.sum()}')\n",
    "  return sig\n",
    "\n",
    "def loss_old(preds, y):\n",
    "  # print(f'preds: {preds[0:5]}')\n",
    "  # print(f'labels: {y[0:5]}')\n",
    "  # print(f'x shape: {preds.shape}, y shape: {y.shape}')\n",
    "  a = (preds - y).abs().mean()\n",
    "  # print(f'a.grad_fn: {a.grad_fn}')\n",
    "  # print(f'a: {a}')\n",
    "  return a\n",
    "\n",
    "def loss(preds, y):\n",
    "    return torch.where(y==1, 1-preds, preds).mean()\n",
    "# loss(predictions(train_x, w, b), train_y)\n",
    "\n",
    "def apply_step(i, x, y, w, b, lr):\n",
    "  preds = predictions(x, w, b)\n",
    "  # print(f'preds.grad_fn: {preds.grad_fn}')\n",
    "  # l = preds.backward()\n",
    "  l = loss(preds, y)\n",
    "  # print(f'l.grad_fn: {l.grad_fn}')\n",
    "  l.backward()\n",
    "  # print(f'w after backward: {w[0:1]}')\n",
    "  # print(f'w grads after backward: {w.grad.shape}, {w.grad[:,0:4]}')\n",
    "  # print(f'w.grad.data: {w.grad.data[0:3]}')\n",
    "  # print(f'before b.data: {b.data}')\n",
    "  # print(f'before b.grad: {b.grad.data}')\n",
    "  w.data = w.data - (w.grad.data * lr)\n",
    "  b.data = b.data - (b.grad.data * lr)\n",
    "  # print(f'after b.grad: {b.grad}')\n",
    "  w.grad = b.grad = None\n",
    "  return (w, b, l)\n",
    "\n",
    "def apply_steps(n, x, y, w, b, lr):\n",
    "  results = []\n",
    "  for i in range(n):\n",
    "    # print(f'before b: {b[0:5]}')\n",
    "    (w, b, l) = apply_step(i, x, y, w, b, lr)\n",
    "    results.append(l)\n",
    "    if(i % 10 == 0): print(f'loss at step({i}): {l}')\n",
    "    # print(f'after b: {b[0:5]}')\n",
    "  return (w, b, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "1VYnI4-KWeDP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 100\n",
      "loss at step(0): 0.7012012004852295\n",
      "loss at step(10): 0.03797343000769615\n",
      "loss at step(20): 0.028245823457837105\n",
      "loss at step(30): 0.023088108748197556\n",
      "loss at step(40): 0.02060992643237114\n",
      "loss at step(50): 0.01920783333480358\n",
      "loss at step(60): 0.018249552696943283\n",
      "loss at step(70): 0.01755746454000473\n",
      "loss at step(80): 0.01704421266913414\n",
      "loss at step(90): 0.01645560748875141\n"
     ]
    }
   ],
   "source": [
    "# Initialise parameters(w & b), initialise learning rate(lr), call gradient descent algorithm\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(5)\n",
    "w = torch.randn((784, 1), generator=g).to(device).requires_grad_(True)\n",
    "# print(f'w: {w[0:1, 0:1]}')\n",
    "# print(f'w cuda? {w.is_cuda}')\n",
    "# print(f'w shape: {w.shape}, w: {w[0:4, 0:4]}')\n",
    "b = torch.randn(1, generator=g).to(device).requires_grad_(True)\n",
    "# print(f'b cuda? {b.is_cuda}')\n",
    "# print(f'len(b): {len(b)}, b: {b[0:9]}')\n",
    "\n",
    "# lrs = [0.001, 0.1, 1, 100, 10000, 100000]\n",
    "lrs = [100]\n",
    "for lr in lrs:\n",
    "  print(f'lr: {lr}')\n",
    "  fw, fb, fr = apply_steps(100, train_x, train_y, w, b, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "OGqdsW4SQGJs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: tensor([[1.8423]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "r.grad_fn: <AddBackward0 object at 0x7f56835dc910>\n",
      "sums.grad_fn: <UnsqueezeBackward0 object at 0x7f56835dc910>\n",
      "sig.grad_fn: <SigmoidBackward0 object at 0x7f56835dc910>\n"
     ]
    }
   ],
   "source": [
    "# Analyse the results of gradient descent\n",
    "\n",
    "#len(range(30)), len(results)\n",
    "#plt.scatter(range(30), to_np(fr))\n",
    "p = predictions(train_x, fw, fb)\n",
    "type(p), len(p), p.shape\n",
    "diff = (p <= 0.5).float().sum()\n",
    "# type(diff), len(diff), diff.shape, diff\n",
    "# diff, len(train_y), loss(p, train_y)\n",
    "\n",
    "# p[0], train_y[0], p[0] - train_y[0]\n",
    "diffs = torch.nonzero((p < 0.5).float().unbind(1)[0])\n",
    "trx = [Image.open(f) for f in (path/'train'/'3').ls().sorted()] + [Image.open(f) for f in (path/'train'/'7').ls().sorted()]\n",
    "\n",
    "# try = [Image.open(f) for f in (path/'train'/'7').ls().sorted()]\n",
    "def images():\n",
    "  for d in diffs[-10:-5]:\n",
    "    print(f'd: {d}, prediction: {p[d]}')\n",
    "    show_image(trx[d])\n",
    "\n",
    "  for i in range(5,10):\n",
    "    print(f'i: {i}, prediction: {p[i]}')\n",
    "    show_image(trx[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "pz13tprtyrmY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nonzero: tensor([[ 1],\n",
      "        [ 3],\n",
      "        [ 4],\n",
      "        [ 5],\n",
      "        [ 7],\n",
      "        [ 8],\n",
      "        [ 9],\n",
      "        [10]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(136, array([28, 32, 36, 40]), array([10, 26, 42, 58]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rough work from here on\n",
    "\n",
    "#??torch.nonzero\n",
    "t = tensor([0,1,0,2,2,3,0,1,1,1,1])\n",
    "print(f'nonzero: {torch.nonzero(t)}')\n",
    "\n",
    "#??torch.linspace\n",
    "a = torch.linspace(1, 9, steps=9).unsqueeze(1)\n",
    "a, a[0], a[1], a[0][0],a[0:3]\n",
    "a = np.array([[1, 2, 3, 4],\n",
    "              [5, 6, 7, 8],\n",
    "              [9, 10, 11, 12],\n",
    "              [13, 14, 15, 16]])\n",
    "a[0:3][0:3][0:3], a[0:3, 0:3]\n",
    "a.sum(), a.sum(0), a.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "khozH93J9Bs-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12396 torch.Size([12396, 784]) <class 'torch.Tensor'> 784 \n",
      " tensor([[0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "12396 torch.Size([12396, 1]) <class 'torch.Tensor'> 1 tensor([[1],\n",
      "        [1],\n",
      "        [1]], device='cuda:0')\n",
      "784 torch.Size([784, 1]) <class 'torch.Tensor'> 1 tensor([[1.8423],\n",
      "        [0.5189]], device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12396,\n",
       " torch.Tensor,\n",
       " tensor([-0.2476, -0.3517,  0.8259,  0.0914,  0.2466, -0.9449, -0.2818], device='cuda:0', grad_fn=<SliceBackward0>))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_x), train_x.shape, type(train_x), len(train_x[0]), '\\n', train_x[0:3, 0:7])\n",
    "print(len(train_y), train_y.shape, type(train_y), len(train_y[0]), train_y[0:3])\n",
    "print(len(w), w.shape, type(w), len(w[0]), w[0:2, 0:3])\n",
    "len(b), type(b), b[0:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "LzlJN9-Pa1kG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], requires_grad=True)\n",
      "a.grad_fn: None\n",
      "b.grad_fn: <AddBackward0 object at 0x7f56835dd780>\n",
      "c.grad_fn: <SumBackward1 object at 0x7f56835dd780>\n",
      "c: tensor([1., 1., 1., 1.], grad_fn=<SumBackward1>)\n",
      "d.grad_fn: <UnsqueezeBackward0 object at 0x7f56835ddf30>\n",
      "d: tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], grad_fn=<UnsqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones((4,1), requires_grad=True)\n",
    "print(f'a: {a}')\n",
    "print(f'a.grad_fn: {a.grad_fn}')\n",
    "b = a + 1\n",
    "print(f'b.grad_fn: {b.grad_fn}')\n",
    "c = a.sum(1)\n",
    "print(f'c.grad_fn: {c.grad_fn}')\n",
    "print(f'c: {c}')\n",
    "d = c.unsqueeze(1)\n",
    "print(f'd.grad_fn: {d.grad_fn}')\n",
    "print(f'd: {d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ESf0JXtsxA_Y"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, w.shape\n",
    "1 + 1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP/u4cg/mwnS/1TpKDUWSaT",
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
